

  分布式优化和推理正在成为解决大规模机器学习问题的流行技术。由于观测数据和参数数据的增长，使用一组机器克服了单个机器无法快速解决这些问题的问题。然而，实现高效的分布式算法并不容易。密集的计算工作量和数据通信量都需要仔细的系统设计。
  
  我们的系统针对的情况超出了典型的集群计算方案，其中适量的同质，专用和高可靠性仅供研究人员使用。也就是说，我们的目标是计算机可能不可靠的云计算环境，工作可能会被抢占，数据可能会丢失，以及网络延迟和临时工作负载导致更多不同的性能状况。例如，可以理解的是，由于偶尔的减速，重启，迁移等，同步操作可能会显著降级，涉及的个别服务器。 换句话说，我们的目标是真正的云计算场景,适用于谷歌，百度，亚马逊，微软等，而不是低利用率，专用，高性能的超级计算机集群。 这需要更稳健的计算方法。
  
  有几种通用的分布式机器学习系统。 基于Hadoop的Mahout和基于Spark的MLI，采用了迭代MapReduce框架。由于Spark保存了状态并优化了执行策略，因此Spark远远优于Hadoop MapReduce，这两种方法都使用同步迭代通信模式。 这使得它们容易受到迭代机器学习算法的非均匀性能分布的影响，即在任何给定时间内机器可能碰巧很慢。为了克服这个限制，分布式GraphLab [21]使用图抽象异步调度通信。 但是，它缺乏基于map / reduce的框架的弹性可伸缩性，并且依靠粗粒度快照进行恢复。 而且，全局变量同步不是一流的基元。 当然，除了这些通用框架之外，还开发了许多针对特定应用的系统。
  
  我们发现许多推理问题在参数化方面的结构相当有限，可以通过利用这种设计获得相当大的收益。例如，广义线性模型通常使用单个大量参数向量，或者主题模型使用稀疏向量数组。一般来说，许多相关的大规模图形模型主要由一个小的模型组成从而允许在观察和机器之间共享少量组件的重复结构。 通过批量执行这些操作并专门为特定数据类型设置同步原语，可以大大提高效率。
  
  我们专注于分布式优化的参数服务器方法。 在这个模型中，计算节点被分成客户端和服务器。 每个客户“拥有”一部分数据和工作量，并且服务器一起维护全局共享参数。 这个架构理念并不新鲜：它已经应用于多种机器学习应用，包括潜在变量模型，图形分布推理和深度学习。 我们的目标是建立一个通用系统，其功能只有以前的工作得到部分支持：
  
  easy to use:全局共享参数表示为（可能稀疏的）矢量和矩阵，这些数据结构对于机器学习应用程序比广泛使用的（键，值）存储或表格更方便。 提供高性能和方便的多线程代数运算，如参数与本地训练数据之间的矢量矩阵乘法，以促进开发应用程序。
  
  efficiency:节点之间的通信是异步的。 重要的是，同步不会阻止计算。 该框架允许算法设计者在算法收敛速度和系统效率之间取得平衡，最佳折衷取决于数据，算法和硬件.
  
  Elastic Scalability(弹性和可伸缩性)：可以添加新节点而无需重新启动运行框架。 这种性质是可取的，例如， 用于流式草图或将参数服务器部署为必须长时间保持可用的在线服务时。 我们使用分布式散列表来允许新的服务器节点随时动态插入到集合中。
