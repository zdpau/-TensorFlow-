

  分布式优化和推理正在成为解决大规模机器学习问题的流行技术。由于观测数据和参数数据的增长，使用一组机器克服了单个机器无法快速解决这些问题的问题。然而，实现高效的分布式算法并不容易。密集的计算工作量和数据通信量都需要仔细的系统设计。
  
  我们的系统针对的情况超出了典型的集群计算方案，其中适量的同质，专用和高可靠性仅供研究人员使用。也就是说，我们的目标是计算机可能不可靠的云计算环境，工作可能会被抢占，数据可能会丢失，以及网络延迟和临时工作负载导致更多不同的性能状况。例如，可以理解的是，由于偶尔的减速，重启，迁移等，同步操作可能会显著降级，涉及的个别服务器。 换句话说，我们的目标是真正的云计算场景,适用于谷歌，百度，亚马逊，微软等，而不是低利用率，专用，高性能的超级计算机集群。 这需要更稳健的计算方法。
  
  有几种通用的分布式机器学习系统。 基于Hadoop的Mahout和基于Spark的MLI，采用了迭代MapReduce框架。由于Spark保存了状态并优化了执行策略，因此Spark远远优于Hadoop MapReduce，这两种方法都使用同步迭代通信模式。 这使得它们容易受到迭代机器学习算法的非均匀性能分布的影响，即在任何给定时间内机器可能碰巧很慢。为了克服这个限制，分布式GraphLab [21]使用图抽象异步调度通信。 但是，它缺乏基于map / reduce的框架的弹性可伸缩性，并且依靠粗粒度快照进行恢复。 而且，全局变量同步不是一流的基元。 当然，除了这些通用框架之外，还开发了许多针对特定应用的系统。
  
  我们发现许多推理问题在参数化方面的结构相当有限，可以通过利用这种设计获得相当大的收益。例如，广义线性模型通常使用单个大量参数向量，或者主题模型使用稀疏向量数组。一般来说，许多相关的大规模图形模型主要由一个小的模型组成从而允许在观察和机器之间共享少量组件的重复结构。 通过批量执行这些操作并专门为特定数据类型设置同步原语，可以大大提高效率。
